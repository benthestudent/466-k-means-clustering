New Tasks: (add tasks here if they come up)
(The following are kinda just ideas. Idk if we need to do all of them, but if we have time, I think we should
try to improve the algorithm)
-Optimization ideas:
    -Run alg hella times, pick the result in which clusters have best density
    -Run alg hella times w diff k values and pick k which gives densest clusters or most accurate clusters
    -f1 score, precision, accuracy (i think we need this idk)
    -check out normalization and see if I (Ben) accidentally broke it by adding the nominal distances to it
    -research other ways to optimize k-means/k-modes
-Slides:
    -problems we faced and attempts at optimization
    -bar graphs of different results with different attempts to improve algorithm
    -slide on how to pick k
    -slide explaining k-modes / k-prototypes approach to categorical and mixed data
        -explain distance method
    -discussion on why k-means might not be the best alg for the data (assuming the results stay kinda bad)



Ben
DONE -create Mushroom class
DONE - nominal distance method (k-modes)
DONE -reassign cluster based on k-modes approach
 -cluster evaluation method to determine density and if clusters are good enough

Daksh
DONE -read/process in data
DONE -store data as arraylist of Mushroom objects
DONE -some way to combine the distances (http://www.econ.upf.edu/~michael/stanford/maeb4.pdf - last few pages explain)
-f1 score method

Filip
DONE -euclidian distance method
-main method
-k-means clustering alg method -> fills hashmap with clusters (essentially done but probably needs tweeking -Ben)
DONE -create Cluster class - contains arraylist of mushrooms, centroid, findDensity

Notes:


Euclidean Dist:
    - For qualitative features using one hot encoding -> euclidean dist 0 if match, 2 if not matching
    - Using softmax function to normalize data